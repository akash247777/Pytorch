{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, Dataset and DataLoader are two important classes that help you efficiently load, preprocess, and iterate over your data during training or evaluation of a machine learning model. They are part of the torch.utils.data module.\n",
    "\n",
    "1. Dataset\n",
    "What it is: A Dataset is an abstract class that represents a collection of data samples (e.g., images, text, etc.). It provides a way to access individual data samples and their corresponding labels.\n",
    "\n",
    "Purpose: It allows you to define how to load and preprocess your data.\n",
    "\n",
    "Key Methods:\n",
    "\n",
    "** _len_(): Returns the total number of samples in the dataset.\n",
    "\n",
    "** _getitem_(index): Returns the data sample and its label at the specified index.\n",
    "\n",
    "Example: Custom Dataset\n",
    "Let's create a custom dataset for a simple example where we have a list of numbers and their squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SquareDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # List of numbers\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # Total number of samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]  # Input number\n",
    "        y = x ** 2            # Label (square of the number)\n",
    "        return x, y\n",
    "\n",
    "# Create a dataset\n",
    "data = [1, 2, 3, 4, 5]\n",
    "dataset = SquareDataset(data)\n",
    "\n",
    "# Access a sample\n",
    "print(dataset[1])  # Output: (2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. DataLoader\n",
    "\n",
    "What it is: A DataLoader is a utility that wraps around a Dataset and provides features like:\n",
    "\n",
    "Batching: Splits the data into smaller batches.\n",
    "\n",
    "Shuffling: Randomly shuffles the data to avoid overfitting.\n",
    "\n",
    "Parallel Loading: Loads data in parallel using multiple workers (for faster data loading).\n",
    "\n",
    "Purpose: It makes it easy to iterate over the dataset in batches during training or evaluation.\n",
    "\n",
    "Example: Using DataLoader\n",
    "\n",
    "Let's use the SquareDataset we created earlier with a DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of inputs: tensor([4, 1])\n",
      "Batch of labels: tensor([16,  1])\n",
      "Batch of inputs: tensor([3, 2])\n",
      "Batch of labels: tensor([9, 4])\n",
      "Batch of inputs: tensor([5])\n",
      "Batch of labels: tensor([25])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "for batch in dataloader:\n",
    "    x, y = batch\n",
    "    print(\"Batch of inputs:\", x)\n",
    "    print(\"Batch of labels:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader , Dataset , TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = torch.arange(12,dtype=torch.float16)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code x = torch.arange(12, dtype=torch.float16) creates a 1-dimensional tensor (a tensor with one axis) containing a sequence of numbers from 0 to 11, with each number represented as a 16-bit floating-point number (float16).\n",
    "\n",
    "Breakdown of the Code:\n",
    "\n",
    "1. `torch.arange(12):`\n",
    "\n",
    "This generates a sequence of numbers starting from `0 `up to but not including` 12`.\n",
    "\n",
    "The sequence is: `[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]`.\n",
    "\n",
    "2. `dtype=torch.float16:`\n",
    "\n",
    "This specifies the data type of the tensor as `float16` (16-bit floating-point).\n",
    "\n",
    "`float16` is a lower-precision floating-point format that uses less memory compared to `float32` or `float64`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader returns in iterator , which we can use to iterate through the indivisual examples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], dtype=torch.float16)\n",
      "tensor([1.], dtype=torch.float16)\n",
      "tensor([2.], dtype=torch.float16)\n",
      "tensor([3.], dtype=torch.float16)\n",
      "tensor([4.], dtype=torch.float16)\n",
      "tensor([5.], dtype=torch.float16)\n",
      "tensor([6.], dtype=torch.float16)\n",
      "tensor([7.], dtype=torch.float16)\n",
      "tensor([8.], dtype=torch.float16)\n",
      "tensor([9.], dtype=torch.float16)\n",
      "tensor([10.], dtype=torch.float16)\n",
      "tensor([11.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "for item in data_loader:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(x,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a DataLoader?\n",
    "A DataLoader is a PyTorch utility that helps you efficiently load and iterate over your data in batches. It is commonly used during training or evaluation of machine learning models.\n",
    "\n",
    "Parameters Explained:\n",
    "\n",
    "1. `x:`\n",
    "\n",
    "* This is the dataset you want to load. It should be an instance of a `Dataset` class (e.g., a custom dataset or a built-in dataset like `TensorDataset`).\n",
    "\n",
    "* Example: If `x` is a list of tensors or a custom dataset, the `DataLoader` will iterate over it.\n",
    "\n",
    "2. `batch_size=4:`\n",
    "\n",
    "* This specifies the number of samples to load in each batch.\n",
    "\n",
    "* Example: If your dataset has 100 samples and batch_size=4, the DataLoader will create 25 batches, each containing 4 samples.\n",
    "\n",
    "3. `shuffle=True:`\n",
    "\n",
    "* This determines whether the data should be shuffled before creating batches.\n",
    "\n",
    "* If `shuffle=True,` the data will be randomly shuffled at the beginning of each epoch (iteration over the entire dataset).\n",
    "\n",
    "* Shuffling is typically used during training to ensure the model doesn't learn any unintended patterns from the order of the data.\n",
    "\n",
    "# Example: Using DataLoader with a TensorDataset\n",
    "\n",
    "Let's say you have a dataset of input features X and corresponding labels y. You can use TensorDataset to wrap them into a dataset and then create a DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[ 9., 10.],\n",
      "        [11., 12.],\n",
      "        [ 7.,  8.],\n",
      "        [ 1.,  2.]])\n",
      "Labels: tensor([0., 1., 1., 0.])\n",
      "Inputs: tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "Labels: tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Example data\n",
    "X = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]], dtype=torch.float32)\n",
    "y = torch.tensor([0, 1, 0, 1, 0, 1], dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "for batch in data_loader:\n",
    "    inputs, labels = batch\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output:\n",
    "\n",
    "Since shuffle=True, the order of the batches will be different each time you run the code. Hereâ€™s an example output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Happens Under the Hood? \n",
    "\n",
    "* The DataLoader takes the dataset (x) and splits it into batches of size batch_size=4.\n",
    "\n",
    "* If shuffle=True, it randomly shuffles the data before creating batches.\n",
    "\n",
    "* During iteration, it returns one batch at a time, containing both the input features and labels.\n",
    "\n",
    "# Key Points:\n",
    "\n",
    "* Batching: The DataLoader splits the dataset into smaller batches for efficient processing.\n",
    "\n",
    "* Shuffling: Shuffling ensures that the model doesn't learn any patterns based on the order of the data.\n",
    "\n",
    "* Flexibility: You can use DataLoader with any dataset, whether it's a custom dataset or a built-in one.\n",
    "\n",
    "# Common Use Cases:\n",
    "\n",
    "* Training: Use shuffle=True to shuffle the data at the beginning of each epoch.\n",
    "\n",
    "* Evaluation: Use shuffle=False to keep the data in its original order.\n",
    "\n",
    "* Large Datasets: Use num_workers to load data in parallel for faster processing.\n",
    "\n",
    "# Summary:\n",
    "\n",
    "* The line data_loader = DataLoader(x, batch_size=4, shuffle=True) creates a DataLoader that:\n",
    "\n",
    "* Iterates over the dataset x.\n",
    "\n",
    "* Splits the data into batches of size 4.\n",
    "\n",
    "* Shuffles the data before creating batches.\n",
    "\n",
    "This is a standard way to prepare your data for training or evaluation in PyTorch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output:\n",
    "\n",
    "Since shuffle=True, the order of the batches will be different each time you run the code. Hereâ€™s an example output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch : 0 [tensor([[ 7.,  8.],\n",
      "        [ 3.,  4.],\n",
      "        [ 1.,  2.],\n",
      "        [11., 12.]]), tensor([1., 1., 0., 1.])]\n",
      "Batch : 1 [tensor([[ 5.,  6.],\n",
      "        [ 9., 10.]]), tensor([0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "for i , batch in enumerate(data_loader):\n",
    "    print(f'Batch : {i}', batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Does This Code Do?\n",
    "\n",
    "1. `enumerate(data_loader):`\n",
    "\n",
    "* The `enumerate` function adds an index (`i`) to each batch as you iterate over the `DataLoader`.\n",
    "\n",
    "* It returns a tuple `(i, batch)`, where:\n",
    "\n",
    "  * i is the batch index (starting from 0).\n",
    "\n",
    "  * batch is the actual batch of data.\n",
    "\n",
    "2. `print(f'Batch: {i}', batch):`\n",
    "\n",
    "* This prints the batch index (`i`) and the corresponding batch of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Output:\n",
    "\n",
    "1. Batch 0:\n",
    "\n",
    "* Contains 4 samples (since `batch_size=4`).\n",
    "\n",
    "* The input features (`X`) are:\n",
    "\n",
    "```pyhton\n",
    "tensor([[ 5.,  6.],\n",
    "        [ 1.,  2.],\n",
    "        [ 9., 10.],\n",
    "        [ 3.,  4.]])\n",
    "```\n",
    "* The corresponding labels (y) are:\n",
    "```python\n",
    "tensor([0., 0., 0., 1.])\n",
    "```\n",
    "\n",
    "2. Batch 1:\n",
    "\n",
    "* Contains the remaining 2 samples (since the dataset has 6 samples in total).\n",
    "\n",
    "* The input features (`X`) are:\n",
    "\n",
    "```pyhton\n",
    "tensor([[11., 12.],\n",
    "        [ 7.,  8.]])\n",
    "```\n",
    "* The corresponding labels (y) are:\n",
    "\n",
    "```python\n",
    "\n",
    "tensor([1., 1.])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 2]), torch.Size([6]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0 \n",
      " X: tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]]) , \n",
      " y: tensor([0., 1., 0., 1., 0.])\n",
      "Batch: 1 \n",
      " X: tensor([[11., 12.]]) , \n",
      " y: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset( torch.Tensor(X), torch.Tensor(y)) ## combine X and Y into a dataset\n",
    "data_loader = DataLoader(dataset, batch_size= 5)\n",
    "for i ,batch in enumerate(data_loader):\n",
    "    print(f'Batch: {i} \\n X: {batch[0]} , \\n y: {batch[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
